{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author__: Bogdan Bintu\n",
    "\n",
    "__Email__: bbintu@g.harvard.edu\n",
    "\n",
    "__Date__:3/4/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import glob,os\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['font.size']=15\n",
    "matplotlib.rcParams['font.family']='Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please specifiy the data/save folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'\\data' #This is the folder containing the .tsv data files\n",
    "save_data = r'\\data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load contact probability derived from imaging (see Part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_med,im_fr,im_med_trans,im_med_cis,im_fr_trans,im_fr_cis,nlen=  pickle.load(\n",
    "    open(save_data+r'/mat_contact_IMR90_untreated.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normalize the proximity matrix derived from imaging and separate the A/B genomic regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of regions/chromosome\n",
    "lens = [76, 80, 66, 63, 60, 55, 53, 48, 40, 43, 44, 44, 33, 30, 31, 30, 33, 33, 33, 33, 31, 31, 51]\n",
    "edges = np.cumsum([0]+lens)\n",
    "#AB identity - this is called based on Hi-C data\n",
    "AB = 'B,B,A,A,B,B,A,A,A,B,A,A,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,A,B,B,B,B,B,B,B,B,A,nan,A,A,A,B,A,B,A,B,A,B,A,B,A,A,A,B,B,B,A,A,A,B,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,B,B,B,A,A,B,A,B,A,A,B,B,B,A,B,B,A,B,A,B,A,B,B,B,B,B,nan,A,B,A,B,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,B,B,A,B,B,A,A,A,B,B,A,B,A,A,B,B,A,B,B,B,B,A,A,B,A,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,A,B,B,A,A,A,B,B,A,B,B,A,A,B,B,B,B,B,A,B,nan,B,A,A,B,A,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,B,B,B,A,B,B,A,A,B,B,B,A,A,B,B,nan,A,A,B,B,B,B,B,B,B,B,B,A,B,B,B,A,B,B,B,B,A,B,A,A,A,B,B,B,A,A,B,B,A,B,B,A,B,B,B,B,B,A,B,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,A,B,B,nan,B,A,A,B,B,A,B,A,B,A,A,A,B,B,A,A,B,B,B,B,B,B,B,B,A,B,B,B,A,A,B,A,B,A,B,B,B,B,B,B,B,B,A,A,A,B,B,A,A,A,A,B,B,A,A,A,B,A,B,B,B,A,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,B,A,A,B,B,B,B,B,A,A,A,B,A,A,A,A,B,B,B,B,B,B,B,A,B,B,B,B,B,B,B,A,A,A,B,A,A,A,B,B,B,nan,B,A,B,B,A,A,A,A,B,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,A,A,B,B,B,B,B,B,B,B,B,A,B,B,A,B,B,B,A,B,B,A,A,nan,A,B,A,B,B,B,B,A,A,B,B,A,B,B,B,B,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,A,nan,B,B,B,B,B,B,B,B,A,B,B,A,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,A,B,B,B,A,B,A,A,A,B,B,B,A,A,B,nan,A,nan,A,B,B,B,B,B,A,A,A,A,B,B,A,B,A,B,B,A,B,B,B,B,B,B,B,B,B,B,A,B,A,A,B,B,B,A,B,B,A,A,B,B,B,A,nan,B,B,B,A,A,A,A,A,B,B,B,B,A,A,B,B,A,B,A,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,B,A,B,B,nan,B,B,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,A,A,B,B,B,A,B,B,B,B,B,A,B,B,A,nan,A,A,B,B,B,B,B,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,B,B,B,A,B,A,B,B,B,B,B,B,B,B,A,A,nan,nan,B,B,B,B,A,B,A,A,B,A,B,B,B,B,B,A,A,A,B,A,A,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,nan,B,B,B,A,B,B,B,A,A,B,B,B,B,B,A,A,A,A,A,B,B,B,A,A,B,nan,B,A,B,B,A,A,A,A,A,A,B,B,B,A,A,A,A,B,B,A,A,A,A,B,B,B,A,A,B,nan,nan,A,A,B,B,B,B,A,B,A,B,A,B,B,B,A,A,B,B,B,A,A,B,A,A,A,A,A,A,B,B,A,B,A,B,A,A,B,B,nan,nan,B,B,B,B,B,B,A,A,A,A,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,B,B,B,B,B,nan,nan,nan,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,A,nan,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,A,B,B,B,B,B,B,A,A,nan,nan,nan,nan,B,A,A,A,A,A,B,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,nan,A,A,A,A,A,A,A,A,A,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B'\n",
    "AB=np.array(AB.split(','))\n",
    "A,B = AB=='A',AB=='B'\n",
    "\n",
    "#contact probability derived from imaging\n",
    "logim = np.log(im_fr[:,:,1])\n",
    "logim_o = logim.copy()\n",
    "for ic in range(len(edges)-1):\n",
    "    logim_o[edges[ic]:edges[ic+1],edges[ic]:edges[ic+1]]=np.nan\n",
    "logim_o[np.isinf(logim_o)]=np.nan\n",
    "\n",
    "\n",
    "for il in range(len(edges)-1):\n",
    "    for jl in range(len(edges)-1):\n",
    "        logim_o[edges[il]:edges[il+1],edges[jl]:edges[jl+1]]-=np.nanmedian(logim_o[edges[il]:edges[il+1],edges[jl]:edges[jl+1]])\n",
    "\n",
    "logim_ord = np.concatenate([np.concatenate([logim_o[A,:][:,A],logim_o[B,:][:,A]]),\n",
    "                np.concatenate([logim_o[A,:][:,B],logim_o[B,:][:,B]])],axis=-1)    \n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "edgeA = np.sum(A)\n",
    "plt.plot([edgeA,edgeA],[0,len(logim_ord)],'k')\n",
    "plt.plot([0,len(logim_ord)],[edgeA,edgeA],'k')\n",
    "plt.imshow(logim_ord,cmap='seismic',vmax=np.log(2.5),vmin=np.log(0.5))#,vmin=-8.25,vmax=-3.5)\n",
    "plt.colorbar()\n",
    "plt.title('Normalized proximity frequency\\n('+str(nlen)+' cells)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Organize the proximity data into histograms and box plots, separating A-A, A-B and B-B interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = logim_ord[:edgeA,:edgeA].ravel()\n",
    "AA = AA[~np.isnan(AA)]\n",
    "fig = plt.figure()\n",
    "h1 = plt.hist(AA,bins=np.linspace(-1.05,1.05,36),normed=True,alpha=0.7,color='r',label='AA');\n",
    "\n",
    "AB = logim_ord[edgeA:,:edgeA].ravel()\n",
    "AB = AB[~np.isnan(AB)]\n",
    "plt.hist(AB,bins=np.linspace(-1.05,1.05,36),normed=True,alpha=0.75,color='gray',label='AB');\n",
    "\n",
    "BB = logim_ord[edgeA:,edgeA:].ravel()\n",
    "BB = BB[~np.isnan(BB)]\n",
    "h2 = plt.hist(BB,bins=np.linspace(-1.05,1.05,36),normed=True,alpha=0.75,color='b',label='BB');\n",
    "\n",
    "\n",
    "\n",
    "plt.xlim([-1,1])\n",
    "\n",
    "np.max(h2[0])\n",
    "1./np.sum(h2[0])\n",
    "yvals = [0,0.025,0.05,0.075]\n",
    "plt.yticks(np.array(yvals)*np.sum(h2[0]),np.array(yvals)*100)\n",
    "\n",
    "xvals = np.round(np.exp(np.linspace(-1,1,4)),1)\n",
    "xvals = [0.35,0.7,1.4,2.8]\n",
    "plt.xticks(np.log(xvals),xvals)\n",
    "plt.xlabel(\"Normalized proximity frequency\")\n",
    "plt.ylabel(\"% of locus pairs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(4,12))\n",
    "labels = ['AA','AB','BB']\n",
    "data = [np.exp(AA),np.exp(AB),np.exp(BB)]\n",
    "data = [AA,AB,BB]\n",
    "bplot = axes.boxplot(data,showfliers=False,patch_artist=True,labels=labels,notch=True,whis =[5,95])\n",
    "colors = ['red','grey','blue']\n",
    "for patch, color in zip(bplot['boxes'],colors):\n",
    "    patch.set_facecolor(color)\n",
    "ticks_ = [0.35,0.7,1.4,2.8]\n",
    "plt.yticks(np.log(ticks_),map(str,ticks_))\n",
    "plt.ylabel('Normalized proximity frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 3D positions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = data_folder\n",
    "\n",
    "experiment = []\n",
    "fid = open(folder+os.sep+r'genomic-scale.tsv','r')\n",
    "lines = np.array([ln[:-1].split('\\t')for ln in fid if len(ln)>0])\n",
    "head = list(lines[0])\n",
    "experiment = np.concatenate([experiment,lines[1::2082,head.index('experiment number')].astype(int)])\n",
    "\n",
    "zxy = np.array(lines[1:,:3][:],dtype=np.float)\n",
    "fid = open(folder+os.sep+r'genomic-scale-with transcription and nuclear bodies.tsv','r')\n",
    "lines = np.array([ln[:-1].split('\\t')for ln in fid if len(ln)>0])\n",
    "\n",
    "head = list(lines[0])\n",
    "experiment = np.concatenate([experiment,lines[1::2082,head.index('experiment number')].astype(int)])\n",
    "\n",
    "zxy = np.concatenate([zxy,np.array(lines[1:,:3][:],dtype=np.float)])\n",
    "zxy = zxy.reshape([-1,2082,3])/1000 #transform to um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the genomic distance dependence of cis- A-A, A-B and B-B interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zxy__ = zxy.reshape([-1,1041,3])\n",
    "lens = [76, 80, 66, 63, 60, 55, 53, 48, 40, 43, 44, 44, 33, 30, 31, 30, 33, 33, 33, 33, 31, 31, 51]\n",
    "#AB identity\n",
    "AB = 'B,B,A,A,B,B,A,A,A,B,A,A,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,A,B,B,B,B,B,B,B,B,A,nan,A,A,A,B,A,B,A,B,A,B,A,B,A,A,A,B,B,B,A,A,A,B,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,B,B,B,A,A,B,A,B,A,A,B,B,B,A,B,B,A,B,A,B,A,B,B,B,B,B,nan,A,B,A,B,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,B,B,A,B,B,A,A,A,B,B,A,B,A,A,B,B,A,B,B,B,B,A,A,B,A,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,A,B,B,A,A,A,B,B,A,B,B,A,A,B,B,B,B,B,A,B,nan,B,A,A,B,A,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,B,B,B,A,B,B,A,A,B,B,B,A,A,B,B,nan,A,A,B,B,B,B,B,B,B,B,B,A,B,B,B,A,B,B,B,B,A,B,A,A,A,B,B,B,A,A,B,B,A,B,B,A,B,B,B,B,B,A,B,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,A,B,B,nan,B,A,A,B,B,A,B,A,B,A,A,A,B,B,A,A,B,B,B,B,B,B,B,B,A,B,B,B,A,A,B,A,B,A,B,B,B,B,B,B,B,B,A,A,A,B,B,A,A,A,A,B,B,A,A,A,B,A,B,B,B,A,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,B,A,A,B,B,B,B,B,A,A,A,B,A,A,A,A,B,B,B,B,B,B,B,A,B,B,B,B,B,B,B,A,A,A,B,A,A,A,B,B,B,nan,B,A,B,B,A,A,A,A,B,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,A,A,B,B,B,B,B,B,B,B,B,A,B,B,A,B,B,B,A,B,B,A,A,nan,A,B,A,B,B,B,B,A,A,B,B,A,B,B,B,B,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,A,nan,B,B,B,B,B,B,B,B,A,B,B,A,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,A,B,B,B,A,B,A,A,A,B,B,B,A,A,B,nan,A,nan,A,B,B,B,B,B,A,A,A,A,B,B,A,B,A,B,B,A,B,B,B,B,B,B,B,B,B,B,A,B,A,A,B,B,B,A,B,B,A,A,B,B,B,A,nan,B,B,B,A,A,A,A,A,B,B,B,B,A,A,B,B,A,B,A,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,B,A,B,B,nan,B,B,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,A,A,B,B,B,A,B,B,B,B,B,A,B,B,A,nan,A,A,B,B,B,B,B,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,B,B,B,A,B,A,B,B,B,B,B,B,B,B,A,A,nan,nan,B,B,B,B,A,B,A,A,B,A,B,B,B,B,B,A,A,A,B,A,A,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,nan,B,B,B,A,B,B,B,A,A,B,B,B,B,B,A,A,A,A,A,B,B,B,A,A,B,nan,B,A,B,B,A,A,A,A,A,A,B,B,B,A,A,A,A,B,B,A,A,A,A,B,B,B,A,A,B,nan,nan,A,A,B,B,B,B,A,B,A,B,A,B,B,B,A,A,B,B,B,A,A,B,A,A,A,A,A,A,B,B,A,B,A,B,A,A,B,B,nan,nan,B,B,B,B,B,B,A,A,A,A,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,B,B,B,B,B,nan,nan,nan,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,A,nan,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,A,B,B,B,B,B,B,A,A,nan,nan,nan,nan,B,A,A,A,A,A,B,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,nan,A,A,A,A,A,A,A,A,A,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B'\n",
    "AB=np.array(AB.split(','))\n",
    "A,B = AB=='A',AB=='B'\n",
    "edges = np.cumsum([0]+lens)\n",
    "coords = lines[1:1042,3]\n",
    "def get_center(coord):\n",
    "    \"\"\"get the center position of a coordinate of format: chr1:1000000-2000000\"\"\"\n",
    "    start,end = np.array(coord.split(':')[-1].split('-'),dtype=int)\n",
    "    return (start+end)/2\n",
    "centers = np.array(map(get_center,coords))\n",
    "def getAA_AB_BB_pairs(A):\n",
    "    A = A.astype(int)\n",
    "    CCs = []\n",
    "    for i in range(len(A)):\n",
    "        for j in range(i+1,len(A)):\n",
    "            CC = A[i]+A[j]\n",
    "            CCs.append(CC)\n",
    "    return np.array(CCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist,cdist,squareform\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "res = 3000000.\n",
    "gen_dists_chr_ints_all = []\n",
    "for i in range(len(lens)):\n",
    "    gen_dists_chr = pdist(centers[edges[i]:edges[i+1],np.newaxis])\n",
    "    gen_dists_chr_ints = (gen_dists_chr/res).astype(int)\n",
    "    gen_dists_chr_ints_all.extend(gen_dists_chr_ints)\n",
    "\n",
    "elems = np.unique(gen_dists_chr_ints_all)\n",
    "dic_AA_AB_BB = {}\n",
    "for i in elems:\n",
    "    dic_AA_AB_BB[(0,i)]=[]\n",
    "    dic_AA_AB_BB[(1,i)]=[]\n",
    "    dic_AA_AB_BB[(2,i)]=[]\n",
    "    \n",
    "for ichr in tqdm(range(len(lens))):\n",
    "    zxy_chr = zxy__[:,edges[ichr]:edges[ichr+1]]\n",
    "    A_chr = A[edges[ichr]:edges[ichr+1]]\n",
    "    AB_chr = getAA_AB_BB_pairs(A_chr)\n",
    "    gen_dists_chr = pdist(centers[edges[ichr]:edges[ichr+1],np.newaxis])\n",
    "    gen_dists_chr_ints = (gen_dists_chr/res).astype(int)\n",
    "    pdists = np.array([pdist(zxy_) for zxy_ in zxy_chr])\n",
    "\n",
    "    for idist in elems:\n",
    "        for iAB in range(3):\n",
    "            keep = (gen_dists_chr_ints==idist)&(AB_chr==iAB)\n",
    "            dic_AA_AB_BB[(iAB,idist)].extend(pdists[:,keep].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = [[],[],[]]\n",
    "for iAB in range(3):\n",
    "    for idist in elems:\n",
    "        dists = np.array(dic_AA_AB_BB[(iAB,idist)])\n",
    "        ct = np.sum(dists<0.5)\n",
    "        good = np.sum(dists>=0)\n",
    "        if ct==0 and good==0:\n",
    "            fr = np.nan\n",
    "        else:\n",
    "            fr = float(ct)/good\n",
    "        probs[iAB].append(fr)\n",
    "        \n",
    "        \n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['font.size']=16\n",
    "matplotlib.rcParams['font.family']='Arial'\n",
    "\n",
    "fig = plt.figure(figsize=(7,3.5))\n",
    "plt.semilogy(elems*res/1000000.,probs[2],'ro-',label='A-A')\n",
    "plt.semilogy(elems*res/1000000.,probs[1],'o-',color='gray',label='A-B')\n",
    "plt.semilogy(elems*res/1000000.,probs[0],'o-',color='b',label='B-B')\n",
    "plt.ylabel('Prioximity frequency')\n",
    "plt.xlabel('Genomic distance (Mb)')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate A and B densities in single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main function for calculating trans densities.\n",
    "def zxy_to_dens(zxy,deltas = [0.5],rgmed=5.8):# [0.1,0.25,0.5,0.75,1]\n",
    "    \"\"\"\n",
    "    This computes the trans densities of A and B for each locus.\n",
    "    It takes a list of cells with positions (in um), \n",
    "    and a list of cutoff distances (in um) \n",
    "    and a radius of gyration for normalizing to. This is the median radius of gyration of all spots across all cels.\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    from scipy.spatial.distance import pdist, squareform,cdist\n",
    "    AB = 'B,B,A,A,B,B,A,A,A,B,A,A,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,A,B,B,B,B,B,B,B,B,A,nan,A,A,A,B,A,B,A,B,A,B,A,B,A,A,A,B,B,B,A,A,A,B,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,B,B,B,A,A,B,A,B,A,A,B,B,B,A,B,B,A,B,A,B,A,B,B,B,B,B,nan,A,B,A,B,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,B,B,A,B,B,A,A,A,B,B,A,B,A,A,B,B,A,B,B,B,B,A,A,B,A,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,A,B,B,A,A,A,B,B,A,B,B,A,A,B,B,B,B,B,A,B,nan,B,A,A,B,A,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,B,B,B,A,B,B,A,A,B,B,B,A,A,B,B,nan,A,A,B,B,B,B,B,B,B,B,B,A,B,B,B,A,B,B,B,B,A,B,A,A,A,B,B,B,A,A,B,B,A,B,B,A,B,B,B,B,B,A,B,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,A,B,B,nan,B,A,A,B,B,A,B,A,B,A,A,A,B,B,A,A,B,B,B,B,B,B,B,B,A,B,B,B,A,A,B,A,B,A,B,B,B,B,B,B,B,B,A,A,A,B,B,A,A,A,A,B,B,A,A,A,B,A,B,B,B,A,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,B,A,A,B,B,B,B,B,A,A,A,B,A,A,A,A,B,B,B,B,B,B,B,A,B,B,B,B,B,B,B,A,A,A,B,A,A,A,B,B,B,nan,B,A,B,B,A,A,A,A,B,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,A,A,B,B,B,B,B,B,B,B,B,A,B,B,A,B,B,B,A,B,B,A,A,nan,A,B,A,B,B,B,B,A,A,B,B,A,B,B,B,B,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,A,nan,B,B,B,B,B,B,B,B,A,B,B,A,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,A,B,B,B,A,B,A,A,A,B,B,B,A,A,B,nan,A,nan,A,B,B,B,B,B,A,A,A,A,B,B,A,B,A,B,B,A,B,B,B,B,B,B,B,B,B,B,A,B,A,A,B,B,B,A,B,B,A,A,B,B,B,A,nan,B,B,B,A,A,A,A,A,B,B,B,B,A,A,B,B,A,B,A,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,B,A,B,B,nan,B,B,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,A,A,B,B,B,A,B,B,B,B,B,A,B,B,A,nan,A,A,B,B,B,B,B,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,B,B,B,A,B,A,B,B,B,B,B,B,B,B,A,A,nan,nan,B,B,B,B,A,B,A,A,B,A,B,B,B,B,B,A,A,A,B,A,A,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,nan,B,B,B,A,B,B,B,A,A,B,B,B,B,B,A,A,A,A,A,B,B,B,A,A,B,nan,B,A,B,B,A,A,A,A,A,A,B,B,B,A,A,A,A,B,B,A,A,A,A,B,B,B,A,A,B,nan,nan,A,A,B,B,B,B,A,B,A,B,A,B,B,B,A,A,B,B,B,A,A,B,A,A,A,A,A,A,B,B,A,B,A,B,A,A,B,B,nan,nan,B,B,B,B,B,B,A,A,A,A,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,B,B,B,B,B,nan,nan,nan,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,A,nan,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,A,B,B,B,B,B,B,A,A,nan,nan,nan,nan,B,A,A,A,A,A,B,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,nan,A,A,A,A,A,A,A,A,A,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B'\n",
    "    AB=np.array(AB.split(','))\n",
    "    lens = [76, 80, 66, 63, 60, 55, 53, 48, 40, 43, 44, 44, 33, 30, 31, 30, 33, 33, 33, 33, 31, 31, 51]\n",
    "    edges = np.cumsum([0]+lens)\n",
    "    A,B = AB=='A',AB=='B'\n",
    "\n",
    "    A,B = np.concatenate([A,A]),np.concatenate([B,B])\n",
    "    A = np.where(A)[0]\n",
    "    B = np.where(B)[0]\n",
    "    dic_densA = [] #A density with the cells\n",
    "    dic_densB = [] #B density with the cells\n",
    "    dic_densA_norm = [] #normalized A density with the cells normalized to have the same scale (rg)\n",
    "    dic_densB_norm = [] #normalized A density with the cells normalized to have the same scale (rg)\n",
    "\n",
    "    M = squareform(pdist(zxy))\n",
    "    rg = np.sqrt(np.nanmean(np.sum((zxy-np.nanmean(zxy,axis=0))**2,-1),-1))\n",
    "    \n",
    "    #exclude cis\n",
    "    for i in range(len(lens)):\n",
    "        M[edges[i]:edges[i+1],edges[i]:edges[i+1]]=np.nan\n",
    "        M[edges[-1]+edges[i]:edges[-1]+edges[i+1],edges[-1]+edges[i]:edges[-1]+edges[i+1]]=np.nan\n",
    "\n",
    "    MB,MA=M[:,B]**2,M[:,A]**2\n",
    "    rgmed_rg_sq = (rgmed/rg)**2\n",
    "    for delta in deltas:\n",
    "        deltasq = 2*delta**2\n",
    "        Bdens_,Adens_ = np.nansum(np.exp(-MB/deltasq*rgmed_rg_sq),axis=-1),np.nansum(np.exp(-MA/deltasq*rgmed_rg_sq),axis=-1)\n",
    "        dic_densA_norm.append(Adens_)\n",
    "        dic_densB_norm.append(Bdens_)\n",
    "        Bdens_,Adens_ = np.nansum(np.exp(-MB/deltasq),axis=-1),np.nansum(np.exp(-MA/deltasq),axis=-1)\n",
    "        dic_densA.append(Adens_)\n",
    "        dic_densB.append(Bdens_)\n",
    "    \n",
    "    ### calculate for random A/B asigment\n",
    "    \n",
    "    AB = AB[np.random.permutation(len(AB))]\n",
    "    A,B = AB=='A',AB=='B'\n",
    "    A,B = np.concatenate([A,A]),np.concatenate([B,B])\n",
    "    A = np.where(A)[0]\n",
    "    B = np.where(B)[0]\n",
    "    \n",
    "    dic_densA_random = []\n",
    "    dic_densB_random = []\n",
    "    dic_densA_norm_random = []\n",
    "    dic_densB_norm_random = []\n",
    "    print M.shape,B.shape,A.shape\n",
    "    MB,MA=M[:,B]**2,M[:,A]**2\n",
    "    rgmed_rg_sq = (rgmed/rg)**2\n",
    "    for delta in deltas:\n",
    "        deltasq = 2*delta**2\n",
    "        Bdens_,Adens_ = np.nansum(np.exp(-MB/deltasq*rgmed_rg_sq),axis=-1),np.nansum(np.exp(-MA/deltasq*rgmed_rg_sq),axis=-1)\n",
    "        dic_densA_norm_random.append(Adens_)\n",
    "        dic_densB_norm_random.append(Bdens_)\n",
    "        Bdens_,Adens_ = np.nansum(np.exp(-MB/deltasq),axis=-1),np.nansum(np.exp(-MA/deltasq),axis=-1)\n",
    "        dic_densA_random.append(Adens_)\n",
    "        dic_densB_random.append(Bdens_)\n",
    "    \n",
    "    return dic_densA,dic_densB,dic_densA_norm,dic_densB_norm,dic_densA_random,dic_densB_random,dic_densA_norm_random,dic_densB_norm_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the density analysis\n",
    "\n",
    "Note: This is slow, so I recommend running it in parallel using ipyparallel\n",
    "\n",
    "First start a terminal in jupyter:\n",
    "Got to:\n",
    "http://localhost:8888/tree and click new>Terminal\n",
    "\n",
    "and then input: >ipcluster start -n 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from ipyparallel import Client\n",
    "rc = Client()\n",
    "print(len(rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res = rc[:40].map_sync(zxy_to_dens,zxy)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "res =np.array(res)\n",
    "np.save(save_data+r'\\densityIMR90Untreated.npy',res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate the average A/B density ratio across regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load(save_data+r'\\densityIMR90Untreated.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = slice(None)\n",
    "#res = resWT\n",
    "AD = res[keep,0,0,:]\n",
    "BD = res[keep,1,0,:]\n",
    "Ad = np.nanmedian(AD.reshape([-1,1041]),0)\n",
    "Bd = np.nanmedian(BD.reshape([-1,1041]),0)\n",
    "ABratio = AD/BD\n",
    "ABratio = np.nanmedian(ABratio.reshape([-1,1041]),0)\n",
    "\n",
    "AD_rnd = res[keep,4,0,:]\n",
    "BD_rnd = res[keep,5,0,:]\n",
    "Ad_rnd = np.nanmedian(AD_rnd.reshape([-1,1041]),0)\n",
    "Bd_rnd = np.nanmedian(BD_rnd.reshape([-1,1041]),0)\n",
    "ABratio_rnd = AD_rnd/BD_rnd\n",
    "ABratio_rnd = np.nanmedian(ABratio_rnd.reshape([-1,1041]),0)\n",
    "\n",
    "AB = 'B,B,A,A,B,B,A,A,A,B,A,A,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,A,B,B,B,B,B,B,B,B,A,nan,A,A,A,B,A,B,A,B,A,B,A,B,A,A,A,B,B,B,A,A,A,B,B,A,B,B,A,B,B,B,B,B,B,B,A,B,B,A,A,B,B,B,A,A,B,A,B,A,A,B,B,B,A,B,B,A,B,A,B,A,B,B,B,B,B,nan,A,B,A,B,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,B,B,A,B,B,A,A,A,B,B,A,B,A,A,B,B,A,B,B,B,B,A,A,B,A,B,A,B,B,A,B,B,B,B,A,B,B,A,B,A,A,B,B,A,A,A,B,B,A,B,B,A,A,B,B,B,B,B,A,B,nan,B,A,A,B,A,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,B,B,B,A,B,B,A,A,B,B,B,A,A,B,B,nan,A,A,B,B,B,B,B,B,B,B,B,A,B,B,B,A,B,B,B,B,A,B,A,A,A,B,B,B,A,A,B,B,A,B,B,A,B,B,B,B,B,A,B,A,B,A,B,B,A,B,B,B,B,B,B,B,A,B,A,B,B,nan,B,A,A,B,B,A,B,A,B,A,A,A,B,B,A,A,B,B,B,B,B,B,B,B,A,B,B,B,A,A,B,A,B,A,B,B,B,B,B,B,B,B,A,A,A,B,B,A,A,A,A,B,B,A,A,A,B,A,B,B,B,A,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,B,A,A,B,B,B,B,B,A,A,A,B,A,A,A,A,B,B,B,B,B,B,B,A,B,B,B,B,B,B,B,A,A,A,B,A,A,A,B,B,B,nan,B,A,B,B,A,A,A,A,B,B,A,B,A,A,A,A,B,B,A,B,B,B,A,B,A,A,B,B,B,B,B,B,B,B,B,A,B,B,A,B,B,B,A,B,B,A,A,nan,A,B,A,B,B,B,B,A,A,B,B,A,B,B,B,B,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,A,nan,B,B,B,B,B,B,B,B,A,B,B,A,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,A,B,A,A,B,B,A,A,A,A,B,B,B,A,B,A,A,A,B,B,B,A,A,B,nan,A,nan,A,B,B,B,B,B,A,A,A,A,B,B,A,B,A,B,B,A,B,B,B,B,B,B,B,B,B,B,A,B,A,A,B,B,B,A,B,B,A,A,B,B,B,A,nan,B,B,B,A,A,A,A,A,B,B,B,B,A,A,B,B,A,B,A,B,A,B,A,B,B,B,B,A,A,B,B,B,B,B,B,A,B,B,nan,B,B,B,A,A,A,A,B,B,A,B,B,B,A,B,B,B,A,A,B,B,B,A,B,B,B,B,B,A,B,B,A,nan,A,A,B,B,B,B,B,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,A,A,B,B,B,B,A,B,A,B,B,B,B,B,B,B,B,A,A,nan,nan,B,B,B,B,A,B,A,A,B,A,B,B,B,B,B,A,A,A,B,A,A,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,B,B,A,B,B,nan,B,B,B,A,B,B,B,A,A,B,B,B,B,B,A,A,A,A,A,B,B,B,A,A,B,nan,B,A,B,B,A,A,A,A,A,A,B,B,B,A,A,A,A,B,B,A,A,A,A,B,B,B,A,A,B,nan,nan,A,A,B,B,B,B,A,B,A,B,A,B,B,B,A,A,B,B,B,A,A,B,A,A,A,A,A,A,B,B,A,B,A,B,A,A,B,B,nan,nan,B,B,B,B,B,B,A,A,A,A,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,B,B,B,B,B,nan,nan,nan,A,A,A,B,B,B,B,B,B,A,B,B,B,B,B,B,A,nan,B,B,nan,nan,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,A,B,B,B,B,B,B,A,A,nan,nan,nan,nan,B,A,A,A,A,A,B,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,B,B,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,A,nan,A,A,A,A,A,A,A,A,A,A,A,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B,B'\n",
    "AB=np.array(AB.split(','))\n",
    "lens = [76, 80, 66, 63, 60, 55, 53, 48, 40, 43, 44, 44, 33, 30, 31, 30, 33, 33, 33, 33, 31, 31, 51]\n",
    "edges = np.cumsum([0]+lens)\n",
    "A,B = AB=='A',AB=='B'\n",
    "\n",
    "\n",
    "xmin,xmax,nbins=0.5,1,23\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "dif = ABratio[A]\n",
    "dif = dif[(~np.isnan(dif))&(~np.isinf(dif))]\n",
    "ct1=plt.hist(dif,bins=np.linspace(xmin,xmax,nbins),normed=True,color='r',alpha=0.75)\n",
    "print('A',np.nanmedian(dif))\n",
    "\n",
    "\n",
    "dif = ABratio[B]\n",
    "dif = dif[(~np.isnan(dif))&(~np.isinf(dif))]\n",
    "print('B',np.nanmedian(dif))\n",
    "ct2=plt.hist(dif,bins=np.linspace(xmin,xmax,nbins),normed=True,color='b',alpha=0.75)\n",
    "\n",
    "\n",
    "dif = ABratio_rnd#[A]\n",
    "dif = dif[(~np.isnan(dif))&(~np.isinf(dif))]\n",
    "dif_rnd=dif.copy()\n",
    "ct1=plt.hist(dif,bins=np.linspace(xmin,xmax,nbins),normed=True,color='k',alpha=0.75)\n",
    "print('Rnd',np.nanmedian(dif))\n",
    "xvals=[0.5,0.75,1]\n",
    "plt.xticks(xvals,xvals)\n",
    "yvals = np.array([0,0.10,0.20])\n",
    "plt.yticks(np.array(yvals)*np.sum(ct2[0]),(yvals*100).astype(int))\n",
    "plt.xlabel(\"Median A/B density ratio\")\n",
    "plt.ylabel(\"% of loci\")\n",
    "plt.ylim([0,np.max(np.array(yvals)*np.sum(ct2[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
